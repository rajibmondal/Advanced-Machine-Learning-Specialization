{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.5"
    },
    "colab": {
      "name": "Copy of RNN-task.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rajibmondal/Advanced-Machine-Learning-Specialization/blob/master/Copy_of_RNN_task.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3dcQ4SC9prZA",
        "colab_type": "text"
      },
      "source": [
        "# Generating names with recurrent neural networks\n",
        "\n",
        "This time you'll find yourself delving into the heart (and other intestines) of recurrent neural networks on a class of toy problems.\n",
        "\n",
        "Struggle to find a name for the variable? Let's see how you'll come up with a name for your son/daughter. Surely no human has expertize over what is a good child name, so let us train RNN instead;\n",
        "\n",
        "It's dangerous to go alone, take these:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZX_a3dYZqHTM",
        "colab_type": "code",
        "outputId": "190485d0-2a39-4b96-a534-5572c025a16c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 228
        }
      },
      "source": [
        "! shred -u setup_google_colab.py\n",
        "! wget https://raw.githubusercontent.com/hse-aml/intro-to-dl/master/setup_google_colab.py -O setup_google_colab.py\n",
        "import setup_google_colab\n",
        "setup_google_colab.setup_week5()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-08-15 16:42:19--  https://raw.githubusercontent.com/hse-aml/intro-to-dl/master/setup_google_colab.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 3792 (3.7K) [text/plain]\n",
            "Saving to: ‘setup_google_colab.py’\n",
            "\n",
            "\rsetup_google_colab.   0%[                    ]       0  --.-KB/s               \rsetup_google_colab. 100%[===================>]   3.70K  --.-KB/s    in 0s      \n",
            "\n",
            "2019-08-15 16:42:19 (60.6 MB/s) - ‘setup_google_colab.py’ saved [3792/3792]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:42.696201Z",
          "start_time": "2018-08-13T20:26:38.104103Z"
        },
        "id": "R_DWvhGcprZJ",
        "colab_type": "code",
        "outputId": "03ceaaf0-8137-48cd-f6ac-5f37661eb08e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "print(tf.__version__)\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import os\n",
        "import sys\n",
        "sys.path.append(\"..\")\n",
        "import keras_utils\n",
        "import tqdm_utils"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.14.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YiWqbZTQprZZ",
        "colab_type": "text"
      },
      "source": [
        "# Load data\n",
        "The dataset contains ~8k earthling names from different cultures, all in latin transcript.\n",
        "\n",
        "This notebook has been designed so as to allow you to quickly swap names for something similar: deep learning article titles, IKEA furniture, pokemon names, etc."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:42.701832Z",
          "start_time": "2018-08-13T20:26:42.697766Z"
        },
        "id": "xkPOfpwuprZc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "start_token = \" \"  # so that the network knows that we're generating a first token\n",
        "\n",
        "# this is the token for padding,\n",
        "# we will add fake pad token at the end of names \n",
        "# to make them of equal size for further batching\n",
        "pad_token = \"#\"\n",
        "\n",
        "with open(\"names\") as f:\n",
        "    names = f.read()[:-1].split('\\n')\n",
        "    names = [start_token + name for name in names]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:42.707885Z",
          "start_time": "2018-08-13T20:26:42.703302Z"
        },
        "id": "kq2URASaprZk",
        "colab_type": "code",
        "outputId": "1c44dde9-2fff-48a5-cd33-4cf533394fc1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        }
      },
      "source": [
        "print('number of samples:', len(names))\n",
        "for x in names[::1000]:\n",
        "    print(x)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "number of samples: 7944\n",
            " Abagael\n",
            " Claresta\n",
            " Glory\n",
            " Liliane\n",
            " Prissie\n",
            " Geeta\n",
            " Giovanne\n",
            " Piggy\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:42.857411Z",
          "start_time": "2018-08-13T20:26:42.709371Z"
        },
        "id": "cblUyaECprZr",
        "colab_type": "code",
        "outputId": "779c68de-c250-43fc-b9f1-98d6c1dad435",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 298
        }
      },
      "source": [
        "MAX_LENGTH = max(map(len, names))\n",
        "print(\"max length:\", MAX_LENGTH)\n",
        "\n",
        "plt.title('Sequence length distribution')\n",
        "plt.hist(list(map(len, names)), bins=25);"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "max length: 16\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYEAAAEICAYAAAC55kg0AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAGntJREFUeJzt3X+UXWV97/H3h/CjgPwIZgyQBCZi\nQIGlAaeAVRAvBcKPS9B7i6FeCIoGWrB6ZV0v0NtCRbpSK6WyxNAAaaBCMOVHSQWESFVKa5AJxpBA\nkAECmTBJBsMPC65o4Hv/2M/oZjhn5vyaOQnP57XWWbPP93n2s7/7THK+Zz97n9mKCMzMLE/btDsB\nMzNrHxcBM7OMuQiYmWXMRcDMLGMuAmZmGXMRMDPLmIuAva1JCknvacN2j5bU28T6l0r6dlreR9J/\nSRrTotyukfQXrcizwthHSnqiVePZyHMRyICkj0j6T0kvS9oo6T8k/X6783o7GcliExHPRcQ7IuL1\nYXI4S9KDNYx3bkRc1orcBu93RPx7RBzQirFtdGzb7gRsZEnaFfgu8CfAQmB74EhgUzvzsvaQNGa4\nYmJ58ZHA29/+ABGxICJej4hfRcR9EbF8oIOkz0h6XNKLku6VtG+p7VhJq9JRxDcl/UjSZ1Pbb6cs\n0vPO9Mlw2/R8N0nXS+qTtFbSVwemNAY+tUr6etruM5JOKI21h6R/lPR8av+XUtvJkpZJeikd4by/\nlhdC0g5pe89JWp+mRXZMbUdL6pV0gaQNKedPl9Z9p6R/lfSKpIfTvjyY2h5I3X6Wpm0+WVqv4ngV\ncpucXttfSloMjBvidT1L0tOp7zOSPiXpfcA1wIdSDi+lvvMlzZF0t6RXgY+l2FcHbf9iSS9IWi3p\nU6X4Dwd+3+XfW7X9Hjy9JOl9aYyXJK2UdEqpbb6kqyXdlfblIUn7Dfd7tNZyEXj7+znwuqQbJJ0g\naWy5UdJ04GLgE0AH8O/AgtQ2Drgd+H8Ub0pPAR+uY9vzgc3Ae4BDgOOAz5baDweeSGN/DbheklLb\nPwE7AQcB7wKuTDkdAswDzgHeCfwDsEjSDjXkM5uiKE5NOU0A/rLUviewW4qfDVxder2uBl5NfWam\nBwARcVRa/ECatvlODeMNdjOwNL0Wl5XHL5O0M3AVcEJE7AL8AbAsIh4HzgV+nHLYvbTaHwOXA7sA\nlaaL9kzbnZC2O1fSsFM6Q+z3QK7bAf8K3EfxO/w8cNOgsWcAfwWMBXpSnjaaIsKPt/kDeB/FG3Iv\nxZvyImB8arsHOLvUdxvgNWBf4ExgSalNaYzPpueXAt8utXcCQTHNOJ5iymnHUvvpwA/S8llAT6lt\np7TunsBewBvA2Ar7Mge4bFDsCeCjVfY9KN7wRfEmvl+p7UPAM2n5aOBXwLal9g3AEcAY4DfAAaW2\nrwIPDt5O6XnV8SrkuE/6vexcit088NoOel13Bl4C/kf5tS29pg8Ois0HbqwQ+2opz8HbXgj8RVr+\n4cDvu9I2qux3b1o+ElgHbFNqXwBcWsrjulLbicCqdv9/ye3hI4EMRMTjEXFWREwEDgb2Bv4+Ne8L\nfCMdrr8EbKR4w5yQ+q0pjRPl58PYF9gO6CuN/Q8UnwgHrCuN/VpafAcwCdgYES9WGfeCgTHTuJNS\nrkPpoCg0S0vrfS/FB/wiIjaXnr+W8umgeAMu73str0O18QbbG3gxIl4txZ6tNGDq80mKT/19aSrl\nvcPkMVyulbY93OtZi72BNRHxxqCxJ5SerystV3t9bAS5CGQmIlZRfAI7OIXWAOdExO6lx44R8Z9A\nH8UbLABpqmZSabhXKd5YB+xZWl5DcSQwrjTurhFxUA1prgH2kLR7lbbLB+W7U0QsGGbMFyg+mR9U\nWm+3iKjlTaef4tPyxFJsUpW+jegDxqapngH7VOscEfdGxLEUR0yrgGsHmqqtMsz2K237+bQ81O94\nOM8DkySV32f2AdbWMYaNMBeBtzlJ700nJyem55MopmWWpC7XABdJOii17ybpj1LbXcBBkj6RTkr+\nGW9+E1gGHKXiOvbdgIsGGiKij2Iu+ApJu0raRtJ+kj46XM5p3XuAb0kaK2k7SQPzz9cC50o6XIWd\nJZ0kaZdhxnwjrXulpHelfZ0g6fga8nmd4tzIpZJ2Sp+8zxzUbT3w7uHGqjL+s0A38FeStpf0EeC/\nV+orabyk6elNexPwXxRTZwM5TJS0fQNpDGz7SOBk4J9TfBnwibTf76E4t1E21H4/RPHp/svpd3h0\n2q9bGsjPRoiLwNvfLylOwD6Urg5ZAqwALgCIiDuAvwFukfRKajshtb0A/BHFCdVfAFOA/xgYOCIW\nA98BllOc1PzuoG2fSXFJ6mPAi8CtFJ9ea3EGxTz8Koq59C+mbXYDnwO+mcbsoZinrsX/Tf2XpH39\nPlDrNe3nU5zkXUdx0noBb77M9lLghjTVdFqNY5b9McXvaSNwCXBjlX7bAF+i+JS9EfgoxeW/AP8G\nrATWSXqhjm2vo3gtnwduAs5NR4xQnJD/NcWb/Q2pvexSqux3RPya4k3/BIojsW8BZ5bGti2Aimle\ns9pI+iHFCcvr2p1LO0n6G2DPiKh4FY/Z1sJHAmY1SNNq709TUIdRTIvc0e68zJrlbwyb1WYXiimg\nvSmmRq4A7mxrRmYt4OkgM7OMeTrIzCxjW/x00Lhx46Kzs7PdaZiZbTWWLl36QkR0DN9zKygCnZ2d\ndHd3tzsNM7OthqSK3zivxNNBZmYZcxEwM8uYi4CZWcZcBMzMMuYiYGaWMRcBM7OMuQiYmWXMRcDM\nLGMuAmZmGdvivzFsW5bOC++qq//q2SeNUCZm1go+EjAzy9iwRUDSJEk/kPSYpJWSvpDie0haLOnJ\n9HNsikvSVZJ6JC2XdGhprJmp/5OSfEcmM7M2q+VIYDNwQUQcCBwBnCfpQOBC4P6ImALcn55DcT/R\nKekxC5gDRdGguHfq4cBhwCUDhcPMzNpj2CIQEX0R8Uha/iXwODABmE5x42nSz1PT8nTgxigsAXaX\ntBdwPLA4IjZGxIvAYmBaS/fGzMzqUtc5AUmdwCHAQ8D4iOhLTeuA8Wl5ArCmtFpvilWLV9rOLEnd\nkrr7+/vrSdHMzOpQcxGQ9A7gNuCLEfFKuS2Ke1S27D6VETE3Iroioqujo6b7IpiZWQNqKgKStqMo\nADdFxO0pvD5N85B+bkjxtcCk0uoTU6xa3MzM2qSWq4MEXA88HhF/V2paBAxc4TMTuLMUPzNdJXQE\n8HKaNroXOE7S2HRC+LgUMzOzNqnly2IfBs4AHpW0LMUuBmYDCyWdDTwLnJba7gZOBHqA14BPA0TE\nRkmXAQ+nfl+JiI0t2QszM2vIsEUgIh4EVKX5mAr9AzivyljzgHn1JGhmZiPH3xg2M8uYi4CZWcZc\nBMzMMuYiYGaWMRcBM7OMuQiYmWXMN5V5m/FNX8ysHj4SMDPLmIuAmVnGXATMzDLmImBmljEXATOz\njLkImJllzEXAzCxjLgJmZhlzETAzy1gtt5ecJ2mDpBWl2HckLUuP1QN3HJPUKelXpbZrSut8UNKj\nknokXZVuW2lmZm1Uy5+NmA98E7hxIBARnxxYlnQF8HKp/1MRMbXCOHOAzwEPUdyCchpwT/0pm5lZ\nqwx7JBARDwAV7wWcPs2fBiwYagxJewG7RsSSdPvJG4FT60/XzMxaqdlzAkcC6yPiyVJssqSfSvqR\npCNTbALQW+rTm2IVSZolqVtSd39/f5MpmplZNc0WgdN581FAH7BPRBwCfAm4WdKu9Q4aEXMjoisi\nujo6OppM0czMqmn4T0lL2hb4BPDBgVhEbAI2peWlkp4C9gfWAhNLq09MMTMza6NmjgT+EFgVEb+d\n5pHUIWlMWn43MAV4OiL6gFckHZHOI5wJ3NnEts3MrAVquUR0AfBj4ABJvZLOTk0zeOsJ4aOA5emS\n0VuBcyNi4KTynwLXAT3AU/jKIDOztht2OigiTq8SP6tC7Dbgtir9u4GD68zPzMxGkL8xbGaWMRcB\nM7OMuQiYmWXMRcDMLGMuAmZmGXMRMDPLmIuAmVnGXATMzDLmImBmljEXATOzjLkImJllzEXAzCxj\nLgJmZhlzETAzy5iLgJlZxlwEzMwyVsudxeZJ2iBpRSl2qaS1kpalx4mltosk9Uh6QtLxpfi0FOuR\ndGHrd8XMzOpVy5HAfGBahfiVETE1Pe4GkHQgxW0nD0rrfEvSmHTf4auBE4ADgdNTXzMza6Nabi/5\ngKTOGsebDtwSEZuAZyT1AIeltp6IeBpA0i2p72N1Z2xmZi3TzDmB8yUtT9NFY1NsArCm1Kc3xarF\nK5I0S1K3pO7+/v4mUjQzs6E0WgTmAPsBU4E+4IqWZQRExNyI6IqIro6OjlYObWZmJcNOB1USEesH\nliVdC3w3PV0LTCp1nZhiDBE3M7M2aehIQNJepacfBwauHFoEzJC0g6TJwBTgJ8DDwBRJkyVtT3Hy\neFHjaZuZWSsMeyQgaQFwNDBOUi9wCXC0pKlAAKuBcwAiYqWkhRQnfDcD50XE62mc84F7gTHAvIhY\n2fK9MTOzutRyddDpFcLXD9H/cuDyCvG7gbvrys7MzEZUQ+cEzEZK54V31b3O6tknjUAmZnnwn40w\nM8uYi4CZWcZcBMzMMuYiYGaWMRcBM7OMuQiYmWXMRcDMLGMuAmZmGXMRMDPLmIuAmVnGXATMzDLm\nImBmljEXATOzjLkImJllzEXAzCxjwxYBSfMkbZC0ohT7W0mrJC2XdIek3VO8U9KvJC1Lj2tK63xQ\n0qOSeiRdJUkjs0tmZlarWo4E5gPTBsUWAwdHxPuBnwMXldqeioip6XFuKT4H+BzFfYenVBjTzMxG\n2bBFICIeADYOit0XEZvT0yXAxKHGSDem3zUilkREADcCpzaWspmZtUorzgl8Brin9HyypJ9K+pGk\nI1NsAtBb6tObYhVJmiWpW1J3f39/C1I0M7NKmioCkv4c2AzclEJ9wD4RcQjwJeBmSbvWO25EzI2I\nrojo6ujoaCZFMzMbQsM3mpd0FnAycEya4iEiNgGb0vJSSU8B+wNrefOU0cQUMzOzNmroSEDSNODL\nwCkR8Vop3iFpTFp+N8UJ4Kcjog94RdIR6aqgM4E7m87ezMyaMuyRgKQFwNHAOEm9wCUUVwPtACxO\nV3ouSVcCHQV8RdJvgDeAcyNi4KTyn1JcabQjxTmE8nkEMzNrg2GLQEScXiF8fZW+twG3VWnrBg6u\nKzszMxtR/sawmVnGXATMzDLmImBmljEXATOzjLkImJllzEXAzCxjLgJmZhlzETAzy5iLgJlZxlwE\nzMwy5iJgZpYxFwEzs4y5CJiZZcxFwMwsYy4CZmYZcxEwM8uYi4CZWcZqKgKS5knaIGlFKbaHpMWS\nnkw/x6a4JF0lqUfSckmHltaZmfo/KWlm63fHzMzqUeuRwHxg2qDYhcD9ETEFuD89BziB4gbzU4BZ\nwBwoigbF/YkPBw4DLhkoHGZm1h41FYGIeADYOCg8HbghLd8AnFqK3xiFJcDukvYCjgcWR8TGiHgR\nWMxbC4uZmY2iZs4JjI+IvrS8DhiflicAa0r9elOsWvwtJM2S1C2pu7+/v4kUzcxsKC05MRwRAUQr\nxkrjzY2Irojo6ujoaNWwZmY2SDNFYH2a5iH93JDia4FJpX4TU6xa3MzM2qSZIrAIGLjCZyZwZyl+\nZrpK6Ajg5TRtdC9wnKSx6YTwcSlmZmZtsm0tnSQtAI4GxknqpbjKZzawUNLZwLPAaan73cCJQA/w\nGvBpgIjYKOky4OHU7ysRMfhks5mZjaKaikBEnF6l6ZgKfQM4r8o484B5NWdnZmYjyt8YNjPLWE1H\nAtYanRfeVVf/1bNPGqFMzMwKPhIwM8uYi4CZWcZcBMzMMuYiYGaWMRcBM7OMuQiYmWXMRcDMLGP+\nnoBlx9/XMPsdHwmYmWXMRcDMLGMuAmZmGXMRMDPLmIuAmVnGXATMzDLWcBGQdICkZaXHK5K+KOlS\nSWtL8RNL61wkqUfSE5KOb80umJlZoxr+nkBEPAFMBZA0huKm8XdQ3E7yyoj4erm/pAOBGcBBwN7A\n9yXtHxGvN5qDmZk1p1XTQccAT0XEs0P0mQ7cEhGbIuIZinsQH9ai7ZuZWQNaVQRmAAtKz8+XtFzS\nPEljU2wCsKbUpzfF3kLSLEndkrr7+/tblKKZmQ3WdBGQtD1wCvDPKTQH2I9iqqgPuKLeMSNibkR0\nRURXR0dHsymamVkVrTgSOAF4JCLWA0TE+oh4PSLeAK7ld1M+a4FJpfUmppiZmbVJK4rA6ZSmgiTt\nVWr7OLAiLS8CZkjaQdJkYArwkxZs38zMGtTUXxGVtDNwLHBOKfw1SVOBAFYPtEXESkkLgceAzcB5\nvjLIzKy9mioCEfEq8M5BsTOG6H85cHkz2zQzs9bxN4bNzDLmImBmljEXATOzjLkImJllzEXAzCxj\nLgJmZhlzETAzy5iLgJlZxlwEzMwy5iJgZpYxFwEzs4y5CJiZZcxFwMwsYy4CZmYZcxEwM8uYi4CZ\nWcZacaP51ZIelbRMUneK7SFpsaQn08+xKS5JV0nqkbRc0qHNbt/MzBrXqiOBj0XE1IjoSs8vBO6P\niCnA/ek5FDeln5Ies4A5Ldq+mZk1YKSmg6YDN6TlG4BTS/Ebo7AE2H3QjenNzGwUtaIIBHCfpKWS\nZqXY+IjoS8vrgPFpeQKwprRub4q9iaRZkroldff397cgRTMzq6SpG80nH4mItZLeBSyWtKrcGBEh\nKeoZMCLmAnMBurq66lrXzMxq1/SRQESsTT83AHcAhwHrB6Z50s8NqftaYFJp9YkpZmZmbdBUEZC0\ns6RdBpaB44AVwCJgZuo2E7gzLS8CzkxXCR0BvFyaNjIzs1HW7HTQeOAOSQNj3RwR35P0MLBQ0tnA\ns8Bpqf/dwIlAD/Aa8Okmt29mZk1oqghExNPAByrEfwEcUyEewHnNbNPMzFrH3xg2M8uYi4CZWcZc\nBMzMMuYiYGaWMRcBM7OMuQiYmWXMRcDMLGMuAmZmGXMRMDPLWCv+iqiZlXReeFdd/VfPPmmEMjEb\nno8EzMwy5iJgZpYxFwEzs4y5CJiZZcxFwMwsYy4CZmYZa7gISJok6QeSHpO0UtIXUvxSSWslLUuP\nE0vrXCSpR9ITko5vxQ6YmVnjmvmewGbggoh4JN1neKmkxantyoj4ermzpAOBGcBBwN7A9yXtHxGv\nN5FDS/n6bjPLTcNHAhHRFxGPpOVfAo8DE4ZYZTpwS0RsiohnKO4zfFij2zczs+a15JyApE7gEOCh\nFDpf0nJJ8ySNTbEJwJrSar0MXTTMzGyENV0EJL0DuA34YkS8AswB9gOmAn3AFQ2MOUtSt6Tu/v7+\nZlM0M7MqmioCkrajKAA3RcTtABGxPiJej4g3gGv53ZTPWmBSafWJKfYWETE3Iroioqujo6OZFM3M\nbAjNXB0k4Hrg8Yj4u1J8r1K3jwMr0vIiYIakHSRNBqYAP2l0+2Zm1rxmrg76MHAG8KikZSl2MXC6\npKlAAKuBcwAiYqWkhcBjFFcWnbclXRlkZpajhotARDwIqELT3UOsczlweaPbNDOz1vI3hs3MMuYi\nYGaWMRcBM7OMuQiYmWXMRcDMLGMuAmZmGXMRMDPLmIuAmVnGmvnGsJm1Qb33vQDf+8Kq85GAmVnG\nXATMzDLmImBmljEXATOzjLkImJllzEXAzCxjLgJmZhlzETAzy9iof1lM0jTgG8AY4LqImD3aOZjZ\n0Or9Qpq/jLb1GtUiIGkMcDVwLNALPCxpUUQ8NhLba+SblWZmORntI4HDgJ6IeBpA0i3AdIqbz5tZ\nJkb6SMN/WqN2iojR25j0P4FpEfHZ9PwM4PCIOH9Qv1nArPT0AOCJUUuyduOAF9qdRIOce3s499G3\nteYNzeW+b0R01NJxi/wDchExF5jb7jyGIqk7IrranUcjnHt7OPfRt7XmDaOX+2hfHbQWmFR6PjHF\nzMysDUa7CDwMTJE0WdL2wAxg0SjnYGZmyahOB0XEZknnA/dSXCI6LyJWjmYOLbRFT1cNw7m3h3Mf\nfVtr3jBKuY/qiWEzM9uy+BvDZmYZcxEwM8uYi0CDJI2R9FNJ3213LvWQtLukWyWtkvS4pA+1O6da\nSPrfklZKWiFpgaTfa3dO1UiaJ2mDpBWl2B6SFkt6Mv0c284cq6mS+9+mfy/LJd0hafd25lhNpdxL\nbRdICknj2pHbcKrlLunz6bVfKelrI7FtF4HGfQF4vN1JNOAbwPci4r3AB9gK9kHSBODPgK6IOJji\nooIZ7c1qSPOBaYNiFwL3R8QU4P70fEs0n7fmvhg4OCLeD/wcuGi0k6rRfN6aO5ImAccBz412QnWY\nz6DcJX2M4i8qfCAiDgK+PhIbdhFogKSJwEnAde3OpR6SdgOOAq4HiIhfR8RL7c2qZtsCO0raFtgJ\neL7N+VQVEQ8AGweFpwM3pOUbgFNHNakaVco9Iu6LiM3p6RKK7/dscaq87gBXAl8GttirYKrk/ifA\n7IjYlPpsGIltuwg05u8p/lG90e5E6jQZ6Af+MU1lXSdp53YnNZyIWEvxKeg5oA94OSLua29WdRsf\nEX1peR0wvp3JNOEzwD3tTqJWkqYDayPiZ+3OpQH7A0dKekjSjyT9/khsxEWgTpJOBjZExNJ259KA\nbYFDgTkRcQjwKlvutMRvpfnz6RRFbG9gZ0n/q71ZNS6K67K32E+l1Uj6c2AzcFO7c6mFpJ2Ai4G/\nbHcuDdoW2AM4Avg/wEJJavVGXATq92HgFEmrgVuA/ybp2+1NqWa9QG9EPJSe30pRFLZ0fwg8ExH9\nEfEb4HbgD9qcU73WS9oLIP0ckUP7kSLpLOBk4FOx9Xy5aD+KDw4/S/9fJwKPSNqzrVnVrhe4PQo/\noZh5aPmJbReBOkXERRExMSI6KU5O/ltEbBWfSiNiHbBG0gEpdAxbx5/xfg44QtJO6ZPQMWwFJ7QH\nWQTMTMszgTvbmEtd0o2gvgycEhGvtTufWkXEoxHxrojoTP9fe4FD0/+DrcG/AB8DkLQ/sD0j8BdR\nXQTy83ngJknLganAX7c5n2GlI5dbgUeARyn+3W6xfw5A0gLgx8ABknolnQ3MBo6V9CTFkc0WeUe9\nKrl/E9gFWCxpmaRr2ppkFVVy3ypUyX0e8O502egtwMyROArzn40wM8uYjwTMzDLmImBmljEXATOz\njLkImJllzEXAzCxjLgJmZhlzETAzy9j/B8WHKERRkkO/AAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8xu1LRVAprZy",
        "colab_type": "text"
      },
      "source": [
        "# Text processing\n",
        "\n",
        "First we need to collect a \"vocabulary\" of all unique tokens i.e. unique characters. We can then encode inputs as a sequence of character ids."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:42.864592Z",
          "start_time": "2018-08-13T20:26:42.858725Z"
        },
        "id": "A_cL8hJcprZ0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "493ea138-d41a-480a-a2a3-1924b3e8e02b"
      },
      "source": [
        "tokens = set(''.join(names[:]))### YOUR CODE HERE: all unique characters go here, padding included!\n",
        "\n",
        "tokens = list(tokens)\n",
        "n_tokens = len(tokens)\n",
        "print ('n_tokens:', n_tokens)\n",
        "\n",
        "assert 50 < n_tokens < 60"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "n_tokens: 55\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KXT8QYW7prZ6",
        "colab_type": "text"
      },
      "source": [
        "### Cast everything from symbols into identifiers\n",
        "\n",
        "Tensorflow string manipulation is a bit tricky, so we'll work around it. \n",
        "We'll feed our recurrent neural network with ids of characters from our dictionary.\n",
        "\n",
        "To create such dictionary, let's assign `token_to_id`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:42.870330Z",
          "start_time": "2018-08-13T20:26:42.866135Z"
        },
        "id": "hzTqtUtGprZ9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "2eac5ec5-9a25-41bf-8d5b-ee4836f93bdb"
      },
      "source": [
        "token_to_id = {} ### YOUR CODE HERE: create a dictionary of {symbol -> its  index in tokens}\n",
        "\n",
        "\n",
        "for i in range(n_tokens):\n",
        "  token_to_id[tokens[i]]=i\n",
        "\n",
        "assert len(tokens) == len(token_to_id), \"dictionaries must have same size\"\n",
        "\n",
        "\n",
        "for i in range(n_tokens):\n",
        "  assert token_to_id[tokens[i]]==i\n",
        "  \n",
        "\n",
        "print(\"seems alright\")"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "seems alright\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:42.875943Z",
          "start_time": "2018-08-13T20:26:42.871834Z"
        },
        "id": "N-mxnTX9praF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def to_matrix(names, max_len=None, pad=0, dtype=np.int32):\n",
        "    \"\"\"Casts a list of names into rnn-digestable padded matrix\"\"\"\n",
        "    \n",
        "    max_len = max_len or max(map(len, names))\n",
        "    \n",
        "    \n",
        "    names_ix = np.zeros([len(names), max_len], dtype) + pad\n",
        "    \n",
        "    \n",
        "\n",
        "    for i in range(len(names)):\n",
        "      \n",
        "        name_ix = list(map(token_to_id.get, names[i]))\n",
        "        \n",
        "        names_ix[i, :len(name_ix)] = name_ix\n",
        "\n",
        "    return names_ix"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:42.883107Z",
          "start_time": "2018-08-13T20:26:42.877186Z"
        },
        "id": "zv_AQYg_praO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        },
        "outputId": "cbe427c4-77d4-44a3-c374-6ca6cf312267"
      },
      "source": [
        "# Example: cast 4 random names to padded matrices (so that we can easily batch them)\n",
        "print('\\n'.join(names[::2000]))\n",
        "print(to_matrix(names[::2000]))"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " Abagael\n",
            " Glory\n",
            " Prissie\n",
            " Giovanne\n",
            "[[48  3 20 21 12 21  0  2  0]\n",
            " [48 42  2  7 44 14  0  0  0]\n",
            " [48 10 44  4 25 25  4  0  0]\n",
            " [48 42  4  7 31 21  9  9  0]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W69bNkQFpraU",
        "colab_type": "text"
      },
      "source": [
        "# Defining a recurrent neural network\n",
        "\n",
        "We can rewrite recurrent neural network as a consecutive application of dense layer to input $x_t$ and previous rnn state $h_t$. This is exactly what we're gonna do now.\n",
        "<img src=\"https://github.com/hse-aml/intro-to-dl/blob/master/week5/rnn.png?raw=1\" width=600>\n",
        "\n",
        "Since we're training a language model, there should also be:\n",
        "* An embedding layer that converts character id x_t to a vector.\n",
        "* An output layer that predicts probabilities of next phoneme based on h_t+1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:44.039419Z",
          "start_time": "2018-08-13T20:26:42.884581Z"
        },
        "id": "4QRUPXJQpraV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 228
        },
        "outputId": "eff2d854-1bb3-4b9d-a5c4-7c491a945a90"
      },
      "source": [
        "# remember to reset your session if you change your graph!\n",
        "s = keras_utils.reset_tf_session()"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0815 17:20:41.505367 140446884173696 deprecation_wrapper.py:119] From /content/keras_utils.py:68: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "W0815 17:20:41.507908 140446884173696 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:79: The name tf.reset_default_graph is deprecated. Please use tf.compat.v1.reset_default_graph instead.\n",
            "\n",
            "W0815 17:20:41.510134 140446884173696 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:82: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "W0815 17:20:41.529304 140446884173696 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:84: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "W0815 17:20:41.530493 140446884173696 deprecation_wrapper.py:119] From /content/keras_utils.py:75: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:44.044903Z",
          "start_time": "2018-08-13T20:26:44.041084Z"
        },
        "id": "IEL-MTCzpraj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import keras\n",
        "from keras.layers import concatenate, Dense, Embedding\n",
        "\n",
        "rnn_num_units = 64  # size of hidden state\n",
        "embedding_size = 16  # for characters\n",
        "\n",
        "# Let's create layers for our recurrent network\n",
        "# Note: we create layers but we don't \"apply\" them yet (this is a \"functional API\" of Keras)\n",
        "# Note: set the correct activation (from keras.activations) to Dense layers!\n",
        "\n",
        "# an embedding layer that converts character ids into embeddings\n",
        "embed_x = Embedding(n_tokens, embedding_size)\n",
        "\n",
        "# a dense layer that maps input and previous state to new hidden state, [x_t,h_t]->h_t+1\n",
        "get_h_next = Dense(rnn_num_units, activation = \"relu\")### YOUR CODE HERE\n",
        "\n",
        "# a dense layer that maps current hidden state to probabilities of characters [h_t+1]->P(x_t+1|h_t+1)\n",
        "get_probas = Dense(n_tokens, activation = \"softmax\")### YOUR CODE HERE "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B7JrR4Wiprao",
        "colab_type": "text"
      },
      "source": [
        "We will generate names character by character starting with `start_token`:\n",
        "\n",
        "<img src=\"https://github.com/hse-aml/intro-to-dl/blob/master/week5/char-nn.png?raw=1\" width=600>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:44.053212Z",
          "start_time": "2018-08-13T20:26:44.048389Z"
        },
        "id": "j0C0xIerprar",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def rnn_one_step(x_t, h_t):\n",
        "    \"\"\"\n",
        "    Recurrent neural network step that produces \n",
        "    probabilities for next token x_t+1 and next state h_t+1\n",
        "    given current input x_t and previous state h_t.\n",
        "    We'll call this method repeatedly to produce the whole sequence.\n",
        "    \n",
        "    You're supposed to \"apply\" above layers to produce new tensors.\n",
        "    Follow inline instructions to complete the function.\n",
        "    \"\"\"\n",
        "    # convert character id into embedding\n",
        "    x_t_emb = embed_x(tf.reshape(x_t, [-1, 1]))[:, 0]\n",
        "    \n",
        "    # concatenate x_t embedding and previous h_t state\n",
        "    x_and_h = tf.concat([x_t_emb, h_t], 1)### YOUR CODE HERE\n",
        "    \n",
        "    # compute next state given x_and_h\n",
        "    h_next = get_h_next(x_and_h)### YOUR CODE HERE\n",
        "    \n",
        "    # get probabilities for language model P(x_next|h_next)\n",
        "    output_probas = get_probas(h_next)### YOUR CODE HERE\n",
        "    \n",
        "    return output_probas, h_next"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lx3WaS8Kpraw",
        "colab_type": "text"
      },
      "source": [
        "# RNN: loop\n",
        "\n",
        "Once `rnn_one_step` is ready, let's apply it in a loop over name characters to get predictions.\n",
        "\n",
        "Let's assume that all names are at most length-16 for now, so we can simply iterate over them in a for loop.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:44.342948Z",
          "start_time": "2018-08-13T20:26:44.056136Z"
        },
        "id": "c3m-B4gMpray",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "input_sequence = tf.placeholder(tf.int32, (None, MAX_LENGTH))  # batch of token ids\n",
        "batch_size = tf.shape(input_sequence)[0]\n",
        "\n",
        "predicted_probas = []\n",
        "h_prev = tf.zeros([batch_size, rnn_num_units])  # initial hidden state\n",
        "\n",
        "for t in range(MAX_LENGTH):\n",
        "    x_t = input_sequence[:, t]  # column t\n",
        "    probas_next, h_next = rnn_one_step(x_t, h_prev)\n",
        "    \n",
        "    h_prev = h_next\n",
        "    predicted_probas.append(probas_next)\n",
        "    \n",
        "# combine predicted_probas into [batch, time, n_tokens] tensor\n",
        "predicted_probas = tf.transpose(tf.stack(predicted_probas), [1, 0, 2])\n",
        "\n",
        "# next to last token prediction is not needed\n",
        "predicted_probas = predicted_probas[:, :-1, :]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vLUJLRTipra3",
        "colab_type": "text"
      },
      "source": [
        "# RNN: loss and gradients\n",
        "\n",
        "Let's gather a matrix of predictions for $P(x_{next}|h)$ and the corresponding correct answers.\n",
        "\n",
        "We will flatten our matrices to shape [None, n_tokens] to make it easier.\n",
        "\n",
        "Our network can then be trained by minimizing crossentropy between predicted probabilities and those answers."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:44.354310Z",
          "start_time": "2018-08-13T20:26:44.344648Z"
        },
        "id": "d1OmvGUZpra5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# flatten predictions to [batch*time, n_tokens]\n",
        "predictions_matrix = tf.reshape(predicted_probas, [-1, n_tokens])\n",
        "\n",
        "# flatten answers (next tokens) and one-hot encode them\n",
        "answers_matrix = tf.one_hot(tf.reshape(input_sequence[:, 1:], [-1]), n_tokens)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JZ7C3duipra-",
        "colab_type": "text"
      },
      "source": [
        "Usually it's a good idea to ignore gradients of loss for padding token predictions.\n",
        "\n",
        "Because we don't care about further prediction after the pad_token is predicted for the first time, so it doesn't make sense to punish our network after the pad_token is predicted.\n",
        "\n",
        "For simplicity you can ignore this comment, it's up to you."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:45.076642Z",
          "start_time": "2018-08-13T20:26:44.355594Z"
        },
        "id": "EASve-_CprbA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        },
        "outputId": "250913f8-fd4c-4db4-8ad0-4c3cfc36bde6"
      },
      "source": [
        "# Define the loss as categorical cross-entropy (e.g. from keras.losses).\n",
        "# Mind that predictions are probabilities and NOT logits!\n",
        "# Remember to apply tf.reduce_mean to get a scalar loss!\n",
        "\n",
        "from keras.objectives import categorical_crossentropy\n",
        "loss = tf.reduce_mean(categorical_crossentropy(answers_matrix, predictions_matrix))#<define loss as categorical crossentropy. Mind that predictions are probabilities and NOT logits!>\n",
        "\n",
        "optimize = tf.train.AdamOptimizer().minimize(loss)"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "W0815 17:44:07.880115 140446884173696 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:2745: calling reduce_sum_v1 (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "keep_dims is deprecated, use keepdims instead\n",
            "W0815 17:44:07.995939 140446884173696 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HiMfZO0VprbH",
        "colab_type": "text"
      },
      "source": [
        "# RNN: training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:55.322187Z",
          "start_time": "2018-08-13T20:26:45.078296Z"
        },
        "id": "iIdnQgleprbI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        },
        "outputId": "7f69f552-95bd-4a9a-f924-4a19670650ff"
      },
      "source": [
        "from IPython.display import clear_output\n",
        "from random import sample\n",
        "\n",
        "s.run(tf.global_variables_initializer())\n",
        "\n",
        "batch_size = 32\n",
        "history = []\n",
        "\n",
        "for i in range(1000):\n",
        "    batch = to_matrix(sample(names, batch_size), max_len=MAX_LENGTH)\n",
        "    loss_i, _ = s.run([loss, optimize], {input_sequence: batch})\n",
        "    \n",
        "    history.append(loss_i)\n",
        "    \n",
        "    if (i + 1) % 100 == 0:\n",
        "        clear_output(True)\n",
        "        plt.plot(history, label='loss')\n",
        "        plt.legend()\n",
        "        plt.show()\n",
        "\n",
        "assert np.mean(history[:10]) > np.mean(history[-10:]), \"RNN didn't converge\""
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nArAAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8esbfn_FprbM",
        "colab_type": "text"
      },
      "source": [
        "# RNN: sampling\n",
        "Once we've trained our network a bit, let's get to actually generating stuff. All we need is the `rnn_one_step` function you have written above."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:55.341196Z",
          "start_time": "2018-08-13T20:26:55.323787Z"
        },
        "id": "VV0qOj0XprbP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_t = tf.placeholder(tf.int32, (1,))\n",
        "h_t = tf.Variable(np.zeros([1, rnn_num_units], np.float32))  # we will update hidden state in this variable\n",
        "\n",
        "# For sampling we need to define `rnn_one_step` tensors only once in our graph.\n",
        "# We reuse all parameters thanks to functional API usage.\n",
        "# Then we can feed appropriate tensor values using feed_dict in a loop.\n",
        "# Note how different it is from training stage, where we had to unroll the whole sequence for backprop.\n",
        "next_probs, next_h = rnn_one_step(x_t, h_t)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:55.346422Z",
          "start_time": "2018-08-13T20:26:55.342659Z"
        },
        "id": "JYx2ytPkprbV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def generate_sample(seed_phrase=start_token, max_length=MAX_LENGTH):\n",
        "    '''\n",
        "    This function generates text given a `seed_phrase` as a seed.\n",
        "    Remember to include start_token in seed phrase!\n",
        "    Parameter `max_length` is used to set the number of characters in prediction.\n",
        "    '''\n",
        "    x_sequence = [token_to_id[token] for token in seed_phrase]\n",
        "    s.run(tf.assign(h_t, h_t.initial_value))\n",
        "    \n",
        "    # feed the seed phrase, if any\n",
        "    for ix in x_sequence[:-1]:\n",
        "         s.run(tf.assign(h_t, next_h), {x_t: [ix]})\n",
        "    \n",
        "    # start generating\n",
        "    for _ in range(max_length-len(seed_phrase)):\n",
        "        x_probs,_ = s.run([next_probs, tf.assign(h_t, next_h)], {x_t: [x_sequence[-1]]})\n",
        "        x_sequence.append(np.random.choice(n_tokens, p=x_probs[0]))\n",
        "        \n",
        "    return ''.join([tokens[ix] for ix in x_sequence if tokens[ix] != pad_token])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:58.458115Z",
          "start_time": "2018-08-13T20:26:55.347900Z"
        },
        "id": "S-MJwgZjprbZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        },
        "outputId": "197a3436-d190-4629-f820-7cd164a274da"
      },
      "source": [
        "# without prefix\n",
        "for _ in range(10):\n",
        "    print(generate_sample())"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " Mhuryseeeeeeeee\n",
            " Arineeeeeeeeeee\n",
            " Bulnieeeeeeeeee\n",
            " Fabriatseeeeeee\n",
            " Alsleeeeeeeeeee\n",
            " Carrichaeeeeeee\n",
            " Libeeeeeeeeeeee\n",
            " Frkankeeeeeeeee\n",
            " Ediaeeeeeeeeeee\n",
            " Ansyeeeeeeeeeee\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:27:01.986726Z",
          "start_time": "2018-08-13T20:26:58.459810Z"
        },
        "id": "jj8ELU0sprbe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        },
        "outputId": "6288a065-b537-483d-e4cd-de0077d66ea3"
      },
      "source": [
        "# with prefix conditioning\n",
        "for _ in range(10):\n",
        "    print(generate_sample(' Trump'))"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " Trumpyeeeeeeeee\n",
            " Trumpilteeeeeee\n",
            " Trumpendeeeeeee\n",
            " Trumpheeeeeeeee\n",
            " Trumpakeeeeeeee\n",
            " Trumpttsayeeeee\n",
            " Trumpyeeeeeeeee\n",
            " Trumpsaaeeeeeee\n",
            " Trumpnptueryeee\n",
            " Trumpathaaeeeee\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1M2_WSIvprbj",
        "colab_type": "text"
      },
      "source": [
        "# Submit to Coursera"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:40:02.004926Z",
          "start_time": "2018-08-13T20:40:02.000821Z"
        },
        "id": "vcO1gQaYprbk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# token expires every 30 min\n",
        "COURSERA_TOKEN = \"uxHz43P1iQqpRdEk\"\n",
        "COURSERA_EMAIL = \"rajueee012@gmail.com\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:40:18.923357Z",
          "start_time": "2018-08-13T20:40:03.549343Z"
        },
        "id": "ds1Q_wR4prbp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "fa5af549-d7e0-49d4-bc09-250ff7d0b3dc"
      },
      "source": [
        "from submit import submit_char_rnn\n",
        "samples = [generate_sample(' Al') for i in tqdm_utils.tqdm_notebook_failsafe(range(25))]\n",
        "submission = (history, samples)\n",
        "submit_char_rnn(submission, COURSERA_EMAIL, COURSERA_TOKEN)"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "*************************\n",
            "\n",
            "Submitted to Coursera platform. See results on assignment page!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JfiyW2epprbu",
        "colab_type": "text"
      },
      "source": [
        "# Try it out!\n",
        "\n",
        "__Disclaimer:__ This part of assignment is entirely optional. You won't receive bonus points for it. However, it's a fun thing to do. Please share your results on course forums.\n",
        "\n",
        "You've just implemented a recurrent language model that can be tasked with generating any kind of sequence, so there's plenty of data you can try it on:\n",
        "\n",
        "* Novels/poems/songs of your favorite author\n",
        "* News titles/clickbait titles\n",
        "* Source code of Linux or Tensorflow\n",
        "* Molecules in [smiles](https://en.wikipedia.org/wiki/Simplified_molecular-input_line-entry_system) format\n",
        "* Melody in notes/chords format\n",
        "* IKEA catalog titles\n",
        "* Pokemon names\n",
        "* Cards from Magic, the Gathering / Hearthstone\n",
        "\n",
        "If you're willing to give it a try, here's what you wanna look at:\n",
        "* Current data format is a sequence of lines, so a novel can be formatted as a list of sentences. Alternatively, you can change data preprocessing altogether.\n",
        "* While some datasets are readily available, others can only be scraped from the web. Try `Selenium` or `Scrapy` for that.\n",
        "* Make sure MAX_LENGTH is adjusted for longer datasets. There's also a bonus section about dynamic RNNs at the bottom.\n",
        "* More complex tasks require larger RNN architecture, try more neurons or several layers. It would also require more training iterations.\n",
        "* Long-term dependencies in music, novels or molecules are better handled with LSTM or GRU\n",
        "\n",
        "__Good hunting!__"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "id": "XF3rwK90prbv",
        "colab_type": "text"
      },
      "source": [
        "# Bonus level: dynamic RNNs\n",
        "\n",
        "Apart from Keras, there's also a friendly TensorFlow API for recurrent neural nets. It's based around the symbolic loop function (aka [tf.scan](https://www.tensorflow.org/api_docs/python/tf/scan)).\n",
        "\n",
        "RNN loop that we implemented for training can be replaced with single TensorFlow instruction: [tf.nn.dynamic_rnn](https://www.tensorflow.org/api_docs/python/tf/nn/dynamic_rnn).\n",
        "This interface allows for dynamic sequence length and comes with some pre-implemented architectures.\n",
        "\n",
        "Take a look at [tf.nn.rnn_cell.BasicRNNCell](https://www.tensorflow.org/api_docs/python/tf/contrib/rnn/BasicRNNCell)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:27:12.975354Z",
          "start_time": "2018-08-13T20:27:12.737529Z"
        },
        "id": "sF1Y-4_5prbw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 176
        },
        "outputId": "63f00eb6-4143-4bf5-f492-8d83f780b5ad"
      },
      "source": [
        "class CustomRNN(tf.nn.rnn_cell.BasicRNNCell):\n",
        "    def call(self, input, state):\n",
        "        # from docs:\n",
        "        # Returns:\n",
        "        # Output: A 2-D tensor with shape [batch_size, self.output_size].\n",
        "        # New state: Either a single 2-D tensor, or a tuple of tensors matching the arity and shapes of state.\n",
        "        return rnn_one_step(input[:, 0], state)\n",
        "    \n",
        "    @property\n",
        "    def output_size(self):\n",
        "        return n_tokens\n",
        "    \n",
        "cell = CustomRNN(rnn_num_units)\n",
        "\n",
        "input_sequence = tf.placeholder(tf.float32, (None, None))\n",
        "    \n",
        "predicted_probas, last_state = tf.nn.dynamic_rnn(cell, input_sequence[:, :, None], dtype=tf.float32)\n",
        "\n",
        "print('LSTM outputs for each step [batch,time,n_tokens]:')\n",
        "print(predicted_probas.eval({input_sequence: to_matrix(names[:10], max_len=50)}).shape)"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "W0815 17:49:44.499513 140446884173696 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "W0815 17:49:44.511021 140446884173696 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/rnn_cell_impl.py:459: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "LSTM outputs for each step [batch,time,n_tokens]:\n",
            "(10, 50, 55)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m6AIAEMcprb1",
        "colab_type": "text"
      },
      "source": [
        "Note that we never used MAX_LENGTH in the code above: TF will iterate over however many time-steps you gave it.\n",
        "\n",
        "You can also use any pre-implemented RNN cell:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:27:12.981697Z",
          "start_time": "2018-08-13T20:27:12.977590Z"
        },
        "id": "oCldM7mrprb2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "60c9bd5a-4996-423a-b94b-bd4315f362da"
      },
      "source": [
        "for obj in dir(tf.nn.rnn_cell) + dir(tf.contrib.rnn):\n",
        "    if obj.endswith('Cell'):\n",
        "        print(obj, end=\"\\t\")"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "BasicLSTMCell\tBasicRNNCell\tGRUCell\tLSTMCell\tMultiRNNCell\tRNNCell\tBasicLSTMCell\tBasicRNNCell\tBidirectionalGridLSTMCell\tConv1DLSTMCell\tConv2DLSTMCell\tConv3DLSTMCell\tConvLSTMCell\tCoupledInputForgetGateLSTMCell\tFusedRNNCell\tGLSTMCell\tGRUBlockCell\tGRUCell\tGridLSTMCell\tIndRNNCell\tIndyGRUCell\tIndyLSTMCell\tIntersectionRNNCell\tLSTMBlockCell\tLSTMBlockFusedCell\tLSTMCell\tLayerNormBasicLSTMCell\tLayerRNNCell\tMultiRNNCell\tNASCell\tPhasedLSTMCell\tRNNCell\tSRUCell\tTimeFreqLSTMCell\tUGRNNCell\t"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6LW1kYXxZ433",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 403
        },
        "outputId": "1ebb1b19-3016-4dee-dc96-340cb9f440e3"
      },
      "source": [
        "input_sequence = tf.placeholder('int32',(None,None))\n",
        "\n",
        "inputs_embedded = embed_x(input_sequence)\n",
        "\n",
        "cell = tf.nn.rnn_cell.LSTMCell(rnn_num_units)\n",
        "\n",
        "state_sequence,last_state = tf.nn.dynamic_rnn(cell,inputs_embedded,dtype='float32')\n",
        "\n",
        "print('LSTM visible states[time,batch,unit]:', state_sequence)"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-57-9311b9d671f4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mcell\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrnn_cell\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLSTMCell\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrnn_num_units\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mstate_sequence\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlast_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdynamic_rnn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcell\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0minputs_embedded\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'float32'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'LSTM visible states[time,batch,unit]:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate_sequence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/util/deprecation.py\u001b[0m in \u001b[0;36mnew_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    322\u001b[0m               \u001b[0;34m'in a future version'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mdate\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'after %s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mdate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m               instructions)\n\u001b[0;32m--> 324\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    325\u001b[0m     return tf_decorator.make_decorator(\n\u001b[1;32m    326\u001b[0m         \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'deprecated'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/rnn.py\u001b[0m in \u001b[0;36mdynamic_rnn\u001b[0;34m(cell, inputs, sequence_length, initial_state, dtype, parallel_iterations, swap_memory, time_major, scope)\u001b[0m\n\u001b[1;32m    705\u001b[0m         \u001b[0mswap_memory\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mswap_memory\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    706\u001b[0m         \u001b[0msequence_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msequence_length\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 707\u001b[0;31m         dtype=dtype)\n\u001b[0m\u001b[1;32m    708\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    709\u001b[0m     \u001b[0;31m# Outputs of _dynamic_rnn_loop are always shaped [time, batch, depth].\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/rnn.py\u001b[0m in \u001b[0;36m_dynamic_rnn_loop\u001b[0;34m(cell, inputs, initial_state, parallel_iterations, swap_memory, sequence_length, dtype)\u001b[0m\n\u001b[1;32m    914\u001b[0m       \u001b[0mparallel_iterations\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparallel_iterations\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    915\u001b[0m       \u001b[0mmaximum_iterations\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtime_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 916\u001b[0;31m       swap_memory=swap_memory)\n\u001b[0m\u001b[1;32m    917\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    918\u001b[0m   \u001b[0;31m# Unpack final output if not using output tuples.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/control_flow_ops.py\u001b[0m in \u001b[0;36mwhile_loop\u001b[0;34m(cond, body, loop_vars, shape_invariants, parallel_iterations, back_prop, swap_memory, name, maximum_iterations, return_same_structure)\u001b[0m\n\u001b[1;32m   3499\u001b[0m       \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_to_collection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGraphKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mWHILE_CONTEXT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloop_context\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3500\u001b[0m     result = loop_context.BuildLoop(cond, body, loop_vars, shape_invariants,\n\u001b[0;32m-> 3501\u001b[0;31m                                     return_same_structure)\n\u001b[0m\u001b[1;32m   3502\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmaximum_iterations\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3503\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/control_flow_ops.py\u001b[0m in \u001b[0;36mBuildLoop\u001b[0;34m(self, pred, body, loop_vars, shape_invariants, return_same_structure)\u001b[0m\n\u001b[1;32m   3010\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_default_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mutation_lock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3011\u001b[0m         original_body_result, exit_vars = self._BuildLoop(\n\u001b[0;32m-> 3012\u001b[0;31m             pred, body, original_loop_vars, loop_vars, shape_invariants)\n\u001b[0m\u001b[1;32m   3013\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3014\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/control_flow_ops.py\u001b[0m in \u001b[0;36m_BuildLoop\u001b[0;34m(self, pred, body, original_loop_vars, loop_vars, shape_invariants)\u001b[0m\n\u001b[1;32m   2935\u001b[0m         expand_composites=True)\n\u001b[1;32m   2936\u001b[0m     \u001b[0mpre_summaries\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_collection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGraphKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_SUMMARY_COLLECTION\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2937\u001b[0;31m     \u001b[0mbody_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbody\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mpacked_vars_for_body\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2938\u001b[0m     \u001b[0mpost_summaries\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_collection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGraphKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_SUMMARY_COLLECTION\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2939\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_sequence_or_composite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbody_result\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/control_flow_ops.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(i, lv)\u001b[0m\n\u001b[1;32m   3454\u001b[0m         cond = lambda i, lv: (  # pylint: disable=g-long-lambda\n\u001b[1;32m   3455\u001b[0m             math_ops.logical_and(i < maximum_iterations, orig_cond(*lv)))\n\u001b[0;32m-> 3456\u001b[0;31m         \u001b[0mbody\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlv\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morig_body\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mlv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3457\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3458\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/rnn.py\u001b[0m in \u001b[0;36m_time_step\u001b[0;34m(time, output_ta_t, state)\u001b[0m\n\u001b[1;32m    882\u001b[0m           skip_conditionals=True)\n\u001b[1;32m    883\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 884\u001b[0;31m       \u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_state\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_cell\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    885\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    886\u001b[0m     \u001b[0;31m# Keras cells always wrap state as list, even if it's a single tensor.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/rnn.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    868\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mis_keras_rnn_cell\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_sequence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    869\u001b[0m       \u001b[0mstate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 870\u001b[0;31m     \u001b[0mcall_cell\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_t\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    871\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    872\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msequence_length\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/rnn_cell_impl.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, state, scope, *args, **kwargs)\u001b[0m\n\u001b[1;32m    383\u001b[0m     \u001b[0;31m# method.  See the class docstring for more details.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    384\u001b[0m     return base_layer.Layer.__call__(\n\u001b[0;32m--> 385\u001b[0;31m         self, inputs, state, scope=scope, *args, **kwargs)\n\u001b[0m\u001b[1;32m    386\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    387\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/layers/base.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    535\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    536\u001b[0m       \u001b[0;31m# Actually call layer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 537\u001b[0;31m       \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mLayer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    538\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    539\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    559\u001b[0m       \u001b[0;31m# framework.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    560\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mbase_layer_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mneeds_keras_history\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 561\u001b[0;31m         \u001b[0mbase_layer_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_keras_history\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    562\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    563\u001b[0m     \u001b[0;31m# Handle Keras mask propagation from previous layer to current layer.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/base_layer_utils.py\u001b[0m in \u001b[0;36mcreate_keras_history\u001b[0;34m(tensors)\u001b[0m\n\u001b[1;32m    198\u001b[0m     \u001b[0mkeras_tensors\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mThe\u001b[0m \u001b[0mTensors\u001b[0m \u001b[0mfound\u001b[0m \u001b[0mthat\u001b[0m \u001b[0mcame\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0ma\u001b[0m \u001b[0mKeras\u001b[0m \u001b[0mLayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m   \"\"\"\n\u001b[0;32m--> 200\u001b[0;31m   \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreated_layers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_create_keras_history_helper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    201\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mcreated_layers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/base_layer_utils.py\u001b[0m in \u001b[0;36m_create_keras_history_helper\u001b[0;34m(tensors, processed_ops, created_layers)\u001b[0m\n\u001b[1;32m    244\u001b[0m             \u001b[0mconstants\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    245\u001b[0m       processed_ops, created_layers = _create_keras_history_helper(\n\u001b[0;32m--> 246\u001b[0;31m           layer_inputs, processed_ops, created_layers)\n\u001b[0m\u001b[1;32m    247\u001b[0m       \u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    248\u001b[0m       \u001b[0mnode_def\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSerializeToString\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/base_layer_utils.py\u001b[0m in \u001b[0;36m_create_keras_history_helper\u001b[0;34m(tensors, processed_ops, created_layers)\u001b[0m\n\u001b[1;32m    244\u001b[0m             \u001b[0mconstants\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    245\u001b[0m       processed_ops, created_layers = _create_keras_history_helper(\n\u001b[0;32m--> 246\u001b[0;31m           layer_inputs, processed_ops, created_layers)\n\u001b[0m\u001b[1;32m    247\u001b[0m       \u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    248\u001b[0m       \u001b[0mnode_def\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSerializeToString\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/base_layer_utils.py\u001b[0m in \u001b[0;36m_create_keras_history_helper\u001b[0;34m(tensors, processed_ops, created_layers)\u001b[0m\n\u001b[1;32m    244\u001b[0m             \u001b[0mconstants\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    245\u001b[0m       processed_ops, created_layers = _create_keras_history_helper(\n\u001b[0;32m--> 246\u001b[0;31m           layer_inputs, processed_ops, created_layers)\n\u001b[0m\u001b[1;32m    247\u001b[0m       \u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    248\u001b[0m       \u001b[0mnode_def\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSerializeToString\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/base_layer_utils.py\u001b[0m in \u001b[0;36m_create_keras_history_helper\u001b[0;34m(tensors, processed_ops, created_layers)\u001b[0m\n\u001b[1;32m    242\u001b[0m             \u001b[0mconstants\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mop_input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    243\u001b[0m           \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 244\u001b[0;31m             \u001b[0mconstants\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    245\u001b[0m       processed_ops, created_layers = _create_keras_history_helper(\n\u001b[1;32m    246\u001b[0m           layer_inputs, processed_ops, created_layers)\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3251\u001b[0m     \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3252\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3253\u001b[0;31m     \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3254\u001b[0m     \u001b[0mfeed_arrays\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3255\u001b[0m     \u001b[0marray_vals\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36mget_session\u001b[0;34m(op_input_list)\u001b[0m\n\u001b[1;32m    460\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0m_MANUAL_VAR_INIT\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    461\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 462\u001b[0;31m       \u001b[0m_initialize_variables\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    463\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    464\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36m_initialize_variables\u001b[0;34m(session)\u001b[0m\n\u001b[1;32m    877\u001b[0m     \u001b[0;31m# marked as initialized.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    878\u001b[0m     is_initialized = session.run(\n\u001b[0;32m--> 879\u001b[0;31m         [variables_module.is_variable_initialized(v) for v in candidate_vars])\n\u001b[0m\u001b[1;32m    880\u001b[0m     \u001b[0muninitialized_vars\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    881\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mflag\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_initialized\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcandidate_vars\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    948\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 950\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    951\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    952\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1156\u001b[0m     \u001b[0;31m# Create a fetch handler to take care of the structure of fetches.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1157\u001b[0m     fetch_handler = _FetchHandler(\n\u001b[0;32m-> 1158\u001b[0;31m         self._graph, fetches, feed_dict_tensor, feed_handles=feed_handles)\n\u001b[0m\u001b[1;32m   1159\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1160\u001b[0m     \u001b[0;31m# Run request and get response.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, graph, fetches, feeds, feed_handles)\u001b[0m\n\u001b[1;32m    485\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    486\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 487\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_assert_fetchable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    488\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetches\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    489\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_assert_fetchable\u001b[0;34m(self, graph, op)\u001b[0m\n\u001b[1;32m    498\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_fetchable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    499\u001b[0m       raise ValueError(\n\u001b[0;32m--> 500\u001b[0;31m           'Operation %r has been marked as not fetchable.' % op.name)\n\u001b[0m\u001b[1;32m    501\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    502\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Operation 'rnn_5/while/IsVariableInitialized' has been marked as not fetchable."
          ]
        }
      ]
    }
  ]
}